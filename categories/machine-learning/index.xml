<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on My Learning Curve</title>
    <link>https://parvezrafi.github.io/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on My Learning Curve</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 11 Dec 2016 22:50:08 +0200</lastBuildDate>
    <atom:link href="https://parvezrafi.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Linear Regression In TensorFlow</title>
      <link>https://parvezrafi.github.io/2016/12/11/linear-regression-in-tensorflow</link>
      <pubDate>Sun, 11 Dec 2016 22:50:08 +0200</pubDate>
      
      <guid>https://parvezrafi.github.io/2016/12/11/linear-regression-in-tensorflow</guid>
      <description>

&lt;p&gt;This article explains how to implement linear regression in using Tensorflow.&lt;/p&gt;

&lt;p&gt;TensorFlow is an open-source library released by Google Brain Team in 2015 for numerical computations using dataflow graphs. Before we dive into implementing Linear Regression algorithm using Tensorflow, let me give you a brief primer on &lt;em&gt;linear regression&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id=&#34;linear-regression:151d92fb75a508007a285feb55442c14&#34;&gt;Linear Regression&lt;/h4&gt;

&lt;p&gt;Regression problem in machine learning means predicting &lt;em&gt;continuous valued outputs&lt;/em&gt;. When regression problem arises in situations, when there exists a nearly linear relation between input and output variables, we classify such problems under &lt;em&gt;linear regression&lt;/em&gt;. For example, let us assume that we were given a probelm to predict the amount of money a person spends in a year. Although, a person&amp;rsquo;s spending may depend on many other factors, but to simplify the problem, let&amp;rsquo;s us focus on the relation between people&amp;rsquo;s expenditures and their incomes. Generally, the relation between people&amp;rsquo;s expenditures and incomes may not be perfectly linear, but when we plot this relation for different people, as depicted by the scatter plot below, there may exist a nearly linear relation between these two quantities.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://parvezrafi.github.io/linear_reg/Spend-vs-income.png&#34; title=&#34;Expenditure V/S Income&#34;&gt;&lt;/p&gt;

&lt;p&gt;The solution to linear regression problem now boils down to finding a linear model which best estimates the behavior of the relation between input(income) and output(expenditure) variables. This best fit continuos linear model then helps us predict an estimate for the expenditure corresponding to any income value. The following graph depicts what we mean by best fit linear model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://parvezrafi.github.io/linear_reg/Best-Fit.png&#34; title=&#34;Best-Fit Linear Model&#34;&gt;&lt;/p&gt;

&lt;p&gt;Mathematically, a linear model can be represented by.&lt;br /&gt;
$y = ax+b$&lt;br /&gt;
where,&lt;br /&gt;
$y$ = independent variable (income in our example)&lt;br /&gt;
$x$ = dependent variable (expenditure in our example)&lt;br /&gt;
$a$ = slope or gradient&lt;br /&gt;
$b$ = intercept&lt;/p&gt;

&lt;p&gt;In order to find best fit, we try minimize the residual variation between out model(hypothesis) and actual output values.&lt;/p&gt;

&lt;p&gt;Best fit :   $min \sum\limits_{i}(y_i - \hat{y_i})^2$&lt;br /&gt;
where $y_i$ = actual output value for $i^{th}$ obervation&lt;br /&gt;
and $\hat{y_i}$ = predicted output value for $i^{th}$ obervation&lt;/p&gt;

&lt;p&gt;In the example presented above, output depended upon single input variable. Such problems are called &lt;em&gt;univariate linear regression&lt;/em&gt;  problems. Practically, the amount a person spends may depend on many other factors or input variables. These problems are then classified as &lt;em&gt;multiivariate linear regression&lt;/em&gt; problems. In such cases, the input is represented by a vector (a list of input variables). To simplify things, we will limit out implementation to univariate linear regression.&lt;/p&gt;

&lt;h4 id=&#34;implentating-linear-regression-using-tensorflow:151d92fb75a508007a285feb55442c14&#34;&gt;Implentating Linear Regression Using TensorFlow&lt;/h4&gt;

&lt;p&gt;First we import necessary libraries.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np
import tensorflow as tf
import matplotlib.patches as mpatches
import matplotlib.pyplot as mplt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we generate x and y data (actual or training data) that will be used as input to train our linear model.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x_data= np.arange(0, 100, 1)
y_data = 0.5*x_data + 1

#Adding some Gaussian noise to y_data
y_data = np.vectorize(lambda y : y + np.random.normal(loc=5.0,scale=5.0))(y_data)
mplt.plot(x_data, y_data, &#39;bo&#39;)
mplt.ylabel(&#39;Expenditure ( x 100)&#39;)
mplt.xlabel(&#39;Income ( x 1,000)&#39;)
mplt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The training data generated above appears as follows.&lt;br /&gt;
&lt;img src=&#34;https://parvezrafi.github.io/linear_reg/Spend-vs-income.png&#34; title=&#34;Expenditure V/S Income&#34;&gt;&lt;/p&gt;

&lt;p&gt;Now we initialize variables a and b in tensorflow. We can give any random initial values to values to $a$ and $b$. The gradient descent optmizer that we implement below, will ultimately optimize these values that represents best linear fit in $y = ax+b$&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a=tf.Variable(1.0)
b=tf.Variable(0.0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we define a linear function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;y=a*x_data + b
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As discussed above, in linear regression we try to minimize residual error between hypothesis and actual y data. For which we find a residual error value.
reduce_mean() function calculates mean of a mathematical function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;residual=tf.reduce_mean(tf.square(y - y_data))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we define the optimizer method. Here we use simple gradient descent of 0.0001 and then we try to minimize the residual error. In tensorflow every operation is executed in a session. So we create session using Session() method. All variables to be used in operations must be initialized first.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;optimizer = tf.train.GradientDescentOptimizer(0.0001)
train = optimizer.minimize(residual)

init=tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)

train_data =[]
for step in range(1000):
    evals = sess.run([train,a,b])[1:]
    if step%50 ==0:
        print(step, evals)
        train_data.append(evals)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the output below, we can see how values of a,b converge to their optimized values that will give us best fit model.&lt;/p&gt;

&lt;p&gt;0 [0.73032355, -0.0037603895]&lt;br /&gt;
50 [0.58921194, 0.0093623158]&lt;br /&gt;
100 [0.58898264, 0.024570402]&lt;br /&gt;
150 [0.58875394, 0.039739955]&lt;br /&gt;
200 [0.58852577, 0.054871064]&lt;br /&gt;
250 [0.58829826, 0.069963828]&lt;br /&gt;
300 [0.58807129, 0.085018359]&lt;br /&gt;
350 [0.58784491, 0.10003471]&lt;br /&gt;
400 [0.58761907, 0.11501303]&lt;br /&gt;
450 [0.58739382, 0.12995344]&lt;br /&gt;
500 [0.58716917, 0.1448559]&lt;br /&gt;
550 [0.58694506, 0.15972069]&lt;br /&gt;
600 [0.58672148, 0.17454772]&lt;br /&gt;
650 [0.5864985, 0.18933743]&lt;br /&gt;
700 [0.58627611, 0.20408921]&lt;br /&gt;
750 [0.58605427, 0.21880373]&lt;br /&gt;
800 [0.58583295, 0.233481]&lt;br /&gt;
850 [0.58561224, 0.24812102]&lt;br /&gt;
900 [0.58539212, 0.26272413]&lt;br /&gt;
950 [0.58517247, 0.27729002]&lt;/p&gt;

&lt;p&gt;Let us plot these values to understand the above convergence better.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;converter = mplt.colors
cr, cg, cb = (1.0,1.0,0.0)
for f in train_data:
    print(cr, cg, cb)
    cb+=1.0/ len(train_data)
    cg-=1.0/len(train_data)
    if cb&amp;gt;1.0: cb=1.0
    if cg&amp;lt;0.0: cg=0.0
    [a,b] = f
    f_y = np.vectorize(lambda x: a*x +b)(x_data)
    line = mplt.plot(x_data, f_y)
    mplt.setp(line, color=(cr,cg,cb))

mplt.plot(x_data, y_data, &#39;bo&#39;)

blue_line = mpatches.Patch(color=&#39;blue&#39;, label=&#39;Data Points&#39;)
pink_line = mpatches.Patch(color=&#39;magenta&#39;, label=&#39;Best Fit Linear Model&#39;)
yellow_line = mpatches.Patch(color=&#39;yellow&#39;, label=&#39;Possible Linear Models&#39;)

mplt.legend(handles=[blue_line, yellow_line, pink_line])
mplt.ylabel(&#39;Expenditure ( x 100)&#39;)
mplt.xlabel(&#39;Income ( x 1,000)&#39;)

mplt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The pink line below represents the best fit linear model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://parvezrafi.github.io/linear_reg/Best-Fit.png&#34; title=&#34;Best-Fit Linear Model&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>